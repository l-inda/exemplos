webpackJsonp([0xc1fa15b5ac71],{1489:function(e,t){e.exports={data:{markdown:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"In the previous section, we have discussed the basic ideas behind most neural network methods: multilayer networks, non-linear activation functions, and learning rules such as the backpropagation algorithm. "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"They power almost all modern neural network applications. However, there are some interesting and powerful variations of the theme that have lead to great advances in deep learning in many areas."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Convolutional neural networks (CNNs)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"One area where deep learning has achieved spectacular success is image processing. The simple classifier that we studied in detail in the previous section is severely limited – as you noticed it wasn't even possible to classify all the smiley faces correctly. By adding more layers in the network and using backpropagation to learn the weights does in principle solve the problem, but another one emerges: the number of weights becomes extremely large and consequently, the amount of training data required to achieve satisfactory accuracy can become too large to be realistic."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Fortunately, a very elegant solution to the problem of too many weights exists: a special kind of neural networks, or rather, a special kind of layer that can be included in a deep neural network. This special kind of layer is a so called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"convolutional layer"}]},{type:"text",value:". Networks including convolutional layers are called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"convolutional neural networks"}]},{type:"text",value:" (CNNs). Their key property is that they can detect image features such as bright or dark (or specific color) spots, edges in various orientations, patterns, and so on. These form the basis for detecting more abstract features such as a cat’s ears, a dog’s snout, a person’s eye, or the octagonal shape of a stop sign. It would normally be hard to train a neural network to detect such features based on the pixels of the input image, because the features can appear in different positions, different orientations, and in different sizes in the image: moving the object or the camera angle will change the pixel values dramatically even if the object itself looks just the same to us. In order to learn to detect a stop sign in all these different conditions would require vast of amounts of training data because the network would only detect the sign in conditions where it has appeared in the training data. So, for example, a stop sign in the top right corner of the image would be detected only if the training data included an image with the stop sign in the top right corner. CNNs can recognize the object anywhere in the image no matter where it has been observed in the training images."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Why we need CNNs",description:"CNNs use a clever trick to reduce the amount of training data required to detect objects in different conditions. The trick basically amounts to using the same input weights for many neurons — so that all of these neurons are activated by the same pattern — but with different input pixels. We can for example have a set of neurons that are activated by a cat’s pointy ear. When the input is a photo of a cat, two neurons are activated, one for the left ear and another for the right. We can also let the neuron’s input pixels be taken from a smaller or a larger area, so that different neurons are activated by the ear appearing in different scales (sizes), so that we can detect a small cat's ears even if the training data only included images of big cats."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The convolutional neurons are typically placed in the bottom layers of the network, which processes the raw input pixels. Basic neurons (like the perceptron neuron discussed above) are placed in the higher layers, which process the output of the bottom layers. The bottom layers can usually be trained using unsupervised learning, without a particular prediction task in mind. Their weights will be tuned to detect features that appear frequently in the input data. Thus, with photos of animals, typical features will be ears and snouts, whereas in images of buildings, the features are architectural components such as walls, roofs, windows, and so on. If a mix of various objects and scenes is used as the input data, then the features learned by the bottom layers will be more or less generic. This means that pre-trained convolutional layers can be reused in many different image processing tasks. This is extremely important since it is easy to get virtually unlimited amounts of unlabeled training data - images without labels - which can be used to train the bottom layers. The top layers are always trained by supervised machine learning techniques such as backpropagation."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"gan",color:"#00B5AA",frombottom:"0",totalheight:"54%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Do neural networks dream of electric sheep? Generative adversarial networks (GANs)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Having learned a neural network from data, it can be used for prediction. Since the top layers of the network have been trained in a supervised manner to perform a particular classification or prediction task, the top layers are really useful only for that task. A network trained to detect stop signs is useless for detecting handwritten digits or cats."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A fascinating result is obtained by taking the pre-trained bottom layers and studying what the features they have learned look like. This can be achieved by generating images that activate a certain set of neurons in the bottom layers. Looking at the generated images, we can see what the neural network “thinks” a particular feature looks like, or what an image with a select set of features in it would look like. Some even like to talk about the networks “dreaming” or “hallucinating” images (see Google’s "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/DeepDream"},children:[{type:"text",value:"DeepDream system"}]},{type:"text",value:")."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Be careful with metaphors",description:"However, we’d like to once again emphasize the problem with metaphors such as dreaming when simple optimization of the input image is meant — remember the suitcase words discussed in Chapter 1. The neural network doesn’t really dream, and it doesn’t have a concept of a cat that it would understand in a similar sense as a human understands. It is simply trained to recognize objects and it can generate images that are similar to the input data that it is trained on."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To actually generate real looking cats, human faces, or other objects (you’ll get whatever you used as the training data), "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/Ian_Goodfellow"},children:[{type:"text",value:"Ian Goodfellow"}]},{type:"text",value:" who currently works at Google Brain, proposed a clever combination of two neural networks. The idea is to let the two networks compete against each other. One of the networks is trained to generate images like the ones in the training data. The other network’s task is to separate images generated by the first network from real images from the training data — it is called the adversarial network, and the whole system is called generative adversarial network or a GAN."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The system trains the two models side by side. In the beginning of the training, the adversarial model has an easy task to tell apart the real images from the training data and the clumsy attempts by the generative model. However, as the generative network slowly gets better and better, the adversarial model has to improve as well, and the cycle continues until eventually the generated images are almost indistinguishable from real ones. The GAN tries to not only reproduce the images in the training data: that would be a way too simple strategy to beat the adversarial network. Rather, the system is trained so that it has to be able to generate new, real-looking images too."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"span",properties:{className:["gatsby-resp-image-wrapper"],style:"position: relative; display: block; ; max-width: 674px; margin-left: auto; margin-right: auto;"},children:[{type:"text",value:"\n    "},{type:"element",tagName:"span",properties:{className:["gatsby-resp-image-background-image"],style:"padding-bottom: 99.85163204747775%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAwH/2gAMAwEAAhADEAAAAevjtlOmE1znRMx54Q//xAAfEAACAQIHAAAAAAAAAAAAAAABAgMAEgQREyEiIzP/2gAIAQEAAQUC2YyANi5clkZiS3KrYjSHquOpN6//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAVEQEBAAAAAAAAAAAAAAAAAAABIP/aAAgBAgEBPwEI/8QAHhAAAgICAgMAAAAAAAAAAAAAAAECERIhIjFBcaH/2gAIAQEABj8CUq2O14GkScaqP0jLSbXdHPHIn7O9KK0SP//EABwQAQADAAIDAAAAAAAAAAAAAAEAESExQWFxgf/aAAgBAQABPyHhhDYsr2QNHyDgQeoJIatIIgNFtLq+deXEdoLZbC6Q17p//9oADAMBAAIAAwAAABCHOEH/xAAXEQEBAQEAAAAAAAAAAAAAAAABABEx/9oACAEDAQE/EFHMJ7bye3//xAAYEQEBAQEBAAAAAAAAAAAAAAABABEhMf/aAAgBAgEBPxBDdYOR4xf/xAAeEAEBAAICAgMAAAAAAAAAAAABEQAhMWFBUXGBof/aAAgBAQABPxBGlCPY2P5l/AUIunnB7HsJ1jTHsqzynrLGh7TUAnGJLNRQwaGXWsfVXT6QuIbQKaLLrOZLQ1+DP//Z'); background-size: cover; display: block;"},children:[{type:"text",value:"\n      "},{type:"element",tagName:"img",properties:{className:["gatsby-resp-image-image"],style:"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px transparent;",alt:"fakecelebrityfaces",title:"",src:"/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-c341a.jpg",srcSet:["/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-24b35.jpg 360w","/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-c341a.jpg 674w"],sizes:["(max-width:","674px)","100vw,","674px"]},children:[]},{type:"text",value:"\n    "}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The above images were generated by a GAN developed by NVIDIA in a project led by "},{type:"element",tagName:"a",properties:{href:"https://users.aalto.fi/~lehtinj7/"},children:[{type:"text",value:"Prof Jaakko Lehtinen"}]},{type:"text",value:" (see "},{type:"element",tagName:"a",properties:{href:"https://www.technologyreview.com/the-download/609290/meet-the-fake-celebrities-dreamed-up-by-ai/"},children:[{type:"text",value:"this article for more details"}]},{type:"text",value:")."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Could you have recognized them as fakes?"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"part-summary",properties:{chapter:"5",heading:"After completing Chapter 5 you should be able to:",listitems:'[ {"content":"Explain what a neural network is and where they are being successfully used"}, {"content":"Understand the technical methods that underpin neural networks"}]'},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]}],data:{quirksMode:!1}},frontmatter:{path:"/5/3",title:"Advanced neural network techniques",section:3,part:5,lang:"en"}},allRelatedSections:{totalCount:3,edges:[{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"Our next topic, deep learning and neural networks, tends to attract more interest than many of the other topics."}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"One of the reasons for the interest is the hope to understand our own mind, which emerges from neural processing in our brain. Another reason is the advances in machine learning achieved within the recent years by combining massive data sets and deep learning techniques."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"What are neural networks?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To better understand the whole, we will start by discussing the individual units that make it up. A neural network can mean either a “real” biological neural network such as the one in your brain, or an artificial neural network simulated in a computer."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"key-terminology",properties:{terminologies:'[{\n\t"title": "Deep learning",\n\t"content": "Deep learning refers to certain kinds of machine learning techniques where several “layers” of simple processing units are connected in a network so that the input to the system is passed through each one of them in turn. This architecture has been inspired by the processing of visual information in the brain coming through the eyes and captured by the retina. This depth allows the network to learn more complex structures without requiring unrealistically large amounts of data."},{\n\t"title": "Neurons, cell bodies, and signals",\n\t"content": "A neural network, either biological and artificial, consists of a large number of simple units, neurons, that receive and transmit signals to each other. The neurons are very very simple processors of information, consisting of a cell body and wires that connect the neurons to each other. Most of the time, they do nothing but sit still and watch for signals coming in through the wires."},{\n\t"title": "Dendrites, axons, and synapses",\n\t"content": "In the biological lingo, we call the wires that provide the input to the neurons dendrites. Sometimes, depending on the incoming signals, the neuron may fire and send a signal out for the other neurons to receive. The wire that transmits the outgoing signal is called an axon. Each axon may be connected to one or more dendrites at intersections that are called synapses."}]'},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:'Isolated from its fellow-neurons, a single neuron is quite unimpressive, and capable of only a very restricted set of behaviors. When connected to each other, however, the system resulting from their concerted action can become extremely complex. To find evidence for this, look no further than (to use legal jargon) "Exhibit A": your brain! The behavior of the system is determined by the ways in which the neurons are wired together. Each neuron reacts to the incoming signals in a specific way that can also adapt over time. This adaptation is known to be the key to functions such as memory and learning.'}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"quiz",properties:{quizid:"5aec60b006ee0000047c599a"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Why develop artificial neural networks?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The purpose of building artificial models of the brain can be neuroscience, the study of the brain and the nervous system in general. It is tempting to think that by mapping the human brain in enough detail, we can discover the secrets of human and animal cognition and consciousness."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"brain"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Modeling the brain",description:"<a href='https://www.braininitiative.nih.gov'>The BRAIN Initiative</a> led by American neuroscience researchers is pushing forward technologies for imaging, modeling, and simulating the brain at a finer and larger scale than before. Some brain research projects are very ambitious in terms of objectives. <a href='https://www.youtube.com/watch?v=JqMpGrM5ECo'>The Human Brain Project</a> promised about 5 years ago that “the mysteries of the mind can be solved - soon”. After years of work, the Human Brain Project was facing questions about when the <a href='https://www.scientificamerican.com/article/why-the-human-brain-project-went-wrong-and-how-to-fix-it/'>billion euros invested by the European Union</a> will deliver what was promised, even though, to be fair, some less ambitious milestones have been achieved."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"However, even while we seem to be almost as far from understanding the mind and consciousness, there are clear milestones that have been achieved in neuroscience. By better understanding of the structure and function of the brain, we are already reaping some concrete rewards. We can, for instance, identify abnormal functioning and try to help the brain avoid them and reinstate normal operation. This can lead to life-changing new medical treatments for people suffering from neurological disorders: epilepsy, Alzheimer’s disease, problems caused by developmental disorders or damage caused by injuries, and so on."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Looking to the future: brain computer interfaces",description:"One research direction in neuroscience is brain-computer interfaces that allow interacting with a computer by simply thinking. The current interfaces are very limited and they can be used, for example, to <a href='https://www.youtube.com/watch?v=Ecvv-EvOj8M'>reconstruct on a very rough level what a person is seeing</a>, or to <a href='https://www.youtube.com/watch?v=7t84lGE5TXA'>control robotic arms or drones by thought</a>. Perhaps some day we can actually implement a thought reading machine that allows precise instructions but currently they belong to science fiction. It is also conceivable that we could feed information into the brain by stimulating it by small electronic pulses. Such stimulation is currently used for therapeutic purposes. Feeding detailed information such as specific words, ideas, memories, or emotions is at least currently science fiction rather than reality, but obviously we know neither the limits of such technology, nor how hard it is to reach them."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We’ve drifted a little astray from the topic of the course. In fact, another main reason for building artificial neural networks has little to do with understanding biological systems. It is to use biological systems as an inspiration to build better AI and machine learning techniques. The idea is very natural: the brain is an amazingly complex information processing system capable of a wide range of intelligent behaviors (plus occasionally some not-so-intelligent ones), and therefore, it makes sense to look for inspiration in it when we try to create artificially intelligent systems."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Neural networks have been a major trend in AI since the 1960s. We’ll return to the waves of popularity in the history of AI in the final part. Currently neural networks are again at the very top of the list as deep learning is used to achieve significant improvements in many areas such as natural language and image processing, which have traditionally been sore points of AI."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"What is so special about neural networks?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The case for neural networks in general as an approach to AI is based on a similar argument as that for logic-based approaches. In the latter case, it was thought that in order to achieve human-level intelligence, we need to simulate higher-level thought processes, and in particular, manipulation of symbols representing certain concrete or abstract concepts using logical rules."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The argument for neural networks is that by simulating the lower-level, “subsymbolic” data processing on the level of neurons and neural networks, intelligence will emerge. This all sounds very reasonable but keep in mind that in order to build flying machines, we don’t build airplanes that flap their wings, or that are made of bones, muscle, and feather. Likewise, in artificial neural networks, the internal mechanism of the neurons is usually ignored and the artificial neurons are often much simpler than their natural counterparts. The eletro-chemical signaling mechanisms between natural neurons are also mostly ignored in artificial models when the goal is to build AI systems rather than to simulate biological systems."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Compared to how computers traditionally work, neural networks have certain special features:"}]},{type:"text",value:"\n"},{type:"element",tagName:"h3",properties:{},children:[{type:"text",value:"Neural network key feature 1"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"For one, in a traditional computer, information is processed in a central processor (aptly named the central processing unit, or CPU for short) which can only focus on doing one thing at a time. The CPU can retrieve data to be processed from the computer’s memory, and store the result in the memory. Thus, data storage and processing are handled by two separate components of the computer: the memory and the CPU. In neural networks, the system consists of a large number of neurons, each of which can process information on its own so that instead of having a CPU process each piece of information one after the other, the neurons process vast amounts of information simultaneously."}]},{type:"text",value:"\n"},{type:"element",tagName:"h3",properties:{},children:[{type:"text",value:"Neural network key feature 2"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The second difference is that data storage (memory) and processing isn’t separated like in traditional computers. The neurons both store and process information so that there is no need to retrieve data from the memory for processing. The data can be stored short term in the neurons themselves (they either fire or not at any given time) or for longer term storage, in the connections between the neurons — their so called weights, which we will discuss below."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Because of these two differences, neural networks and traditional computers are suited for somewhat different tasks. Even though it is entirely possible to simulate neural networks in traditional computers, which was the way they were used for a long time, their maximum capacity is achieved only when we use special hardware (computer devices) that can process many pieces of information at the same time. This is called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"parallel processing"}]},{type:"text",value:". Incidentally, graphics processors (or graphics processing units, GPUs) have this capability and they have become a cost-effective solution for running massive deep learning methods."}]}],data:{quirksMode:!1}},excerpt:"One of the reasons for the interest is the hope to understand our own mind, which emerges from neural processing in our brain. Another…",frontmatter:{path:"/5/1",title:"Neural network basics",part:5,type:"section",lang:"en",section:1}}},{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"As we said earlier, neurons are very simple processing units. Having discussed linear and logistic regression in Chapter 4, the essential technical details of neural networks can be seen as slight variations of the same idea."}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Weights and inputs",description:"The basic artificial neuron model involves a set of adaptive parameters, called weights like in linear and logistic regression. Just like in regression, these weights are used as multipliers on the inputs of the neuron, which are added up. The sum of the weights times the inputs is called the linear combination of the inputs. You can probably recall the shopping bill analogy: you multiply the amount of each item by its price per unit and add up to get the total."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"If we have a neuron with six inputs (analogous to the amounts of the six shopping items: potatoes, carrots, and so on), input1, input2, input3, input4, input5, and input6, we also need six weights. The weights are analogous to the prices of the items. We’ll call them weight1, weight2, weight3, weight4, weight5, and weight6. In addition, we’ll usually want to include an intercept term like we did in linear regression. This can be thought of as a fixed additional charge due to processing a credit card payment, for example."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We can then calculate the linear combination like this: linear combination = intercept + weight1 × input1 + ... + weight6 × input6\n(where the ... is a shorthand notation meaning that the sum include all the terms from 1 to 6)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"With some example numbers we could then get:"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"codesnippet",properties:{text:"10.0 + 5.4 × 8 + (-10.2) × 5 + (-0.1) × 22 + 101.4 × (-5) + 0.0 × 2 + 12.0 × (-3) = -543.0"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"quiz",properties:{quizid:"5af55153bc22a00004917f84"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The weights are almost always learned from data using the same ideas as in linear or logistic regression, as discussed previously. But before we discuss this in more detail, we’ll introduce another important stage that a neuron completes before it sends out an output signal."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Activations and outputs"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Once the linear combination has been computed, the neuron does one more operation. It takes the linear combination and puts it through a so called activation function. Typical examples of the activation function include:"}]},{type:"text",value:"\n"},{type:"element",tagName:"ul",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"identity function: do nothing and just output the linear combination"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"step function: if the value of the linear combination is greater than zero, send a pulse (ON), otherwise do nothing (OFF)"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"sigmoid function: a “soft” version of the step function"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Note that with the first activation function, the identity function, the neuron is exactly the same as linear regression. This is why the identity function is rarely used in neural networks: it leads to nothing new and interesting."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"How neurons activate",description:"Real, biological neurons communicate by sending out sharp, electrical pulses called “spikes”, so that at any given time, their outgoing signal is either on or off (1 or 0). The step function imitates this behavior. However, artificial neural networks tend to use the second kind of activation functions so that they output a continuous numerical activation level at all times. Thus, to use a somewhat awkward figure of speech, real neurons communicate by something similar to the Morse code, whereas artificial neurons communicate by adjusting the pitch of their voice as if yodeling."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"
},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"carstop",color:"#ebe9ef",frombottom:"0",totalheight:"35%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The output of the neuron, determined by the linear combination and the activation function, can be used to extract a prediction or a decision. For example, if the network is designed to identify a stop sign in front of a self-driving car, the input can be the pixels of an image captured by a camera attached in front of the car, and the output can be used to activate a stopping procedure that stops the car before the sign."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Learning or adaptation in the network occurs when the weights are adjusted so as to make the network produce the correct outputs, just like in linear or logistic regression. Many neural networks are very large, and the largest contain hundreds of billions of weights. Optimizing them all can be a daunting task that requires massive amounts of computing power."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise22",properties:{quizid:"5aec5e3a06ee0000047c5994"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Perceptron: the mother of all ANNs"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The perceptron is simply a fancy name for the simple neuron model with the step activation function we discussed above. It was among the very first formal models of neural computation and because of its fundamental role in the history of neural networks, it wouldn’t be unfair to call it the “Mother of all Artificial Neural Networks”."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"It can be used as a simple classifier in binary classification tasks. A method for learning the weights of the perceptron from data, called the Perceptron algorithm, was introduced by the psychologist Frank Rosenblatt in 1957. We will not study the Perceptron algorithm in detail. Suffice to say that it is just about as simple as the nearest neighbor classifier. The basic principle is to feed the network training data one example at a time. Each misclassification leads to an update in the weight."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"AI hyperbole",description:"After its discovery, the Perceptron algorithm received a lot of attention, not least because of optimistic statements made by its inventor, Frank Rosenblatt. A classic example of AI hyperbole is a New York Times article published on July 8th, 1958:<br>“The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, reproduce itself and be conscious of its existence.”<br><br>Please note that neural network enthusiasts are not at all the only ones inclined towards optimism. The rise and fall of the logic-based expert systems approach to AI had all the same hallmark features of an AI-hype and people claimed that the final breakthrough is just a short while away. The outcome both in the early 1960s and late 1980s was a collapse in the research funding called an AI Winter."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The history of the debate that eventually lead to almost complete abandoning of the neural network approach in the 1960s for more than two decades is extremely fascinating. The article "},{type:"element",tagName:"i",properties:{},children:[{type:"element",tagName:"a",properties:{href:"http://journals.sagepub.com/doi/10.1177/030631296026003005"},children:[{type:"text",value:"A Sociological Study of the Official History of the Perceptrons Controversy"}]}]},{type:"text",value:" by Mikel Olazaran (published in "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"Social Studies of Science"}]},{type:"text",value:", 1996) reviews the events from a sociology of science point of view. Reading it today is quite thought provoking. Reading stories about celebrated AI heroes who had developed neural networks algorithms that would soon reach the level of human intelligence and become self-conscious can be compared to some statements made during the current hype. If you take a look at the above article, even if you wouldn't read all of it, it will provide an interesting background to today's news. Consider for example an "},{type:"element",tagName:"a",properties:{href:"https://www.technologyreview.com/s/608911/is-ai-riding-a-one-trick-pony/"},children:[{type:"text",value:"article in the MIT Technology Review"}]},{type:"text",value:" published in September 2017, where Jordan Jacobs, co-founder of a multimillion dollar Vector institute for AI compares Geoffrey Hinton (a figure-head of the current deep learning boom) to Einstein because of his contributions to development of neural network algorithms in the 1980s and later. Also recall the Human Brain project mentioned in the previous section."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"According to Hinton, “the fact that it doesn’t work is just a temporary annoyance.” (Although according to the article, Hinton is laughing about the above statement, so it's hard to tell how serious he is about it.) The Human Brain project claims to be "},{type:"element",tagName:"a",properties:{href:"https://www.humanbrainproject.eu/en/follow-hbp/news/the-quest-for-consciousness/"},children:[{type:"text",value:"“close to a profound leap in our understanding of consciousness“"}]},{type:"text",value:". Doesn't that sound familiar?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"No-one really knows the future with certainty, but knowing the track record of earlier annoucements of imminent breakthroughs, some critical thinking is advised. We'll return to the future of AI in the final Chapter, but for now, let's see how artificial neural networks are built."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Putting neurons together: networks"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A single neuron would be way too simple to make decisions and prediction reliably in most real-life applications. To unleash the full potential of neural networks, we can use the the output of one neuron as the input of other neurons, whose outputs can be the input to yet other neurons, and so on. The output of the whole network is obtained as the output of a certain subset of the neurons, which are called the output layer. We’ll return to this in a bit, after we discussed the way neural networks adapt to produce different behaviors by learning their parameters from data."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"key-terminology",properties:{terminologies:'[\n      {"title":"Layers","content":"Often the network architecture is composed of layers. The input layer consists of neurons that get their inputs directly from the data. So for example, in an image recognition task, the input layer would use the pixel values of the input image as the inputs of the input layer. The network typically also has hidden layers that use the other neurons´ outputs as their input, and whose output is used as the input to other layers of neurons. Finally, the output layer produces the output of the whole network. All the neurons on a given layer get inputs from neurons on the previous layer and feed their output to the next."}\n  ]'},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A classical example of a multilayer network is the so called multilayer perceptron. As we discussed above, Rosenblatt’s Perceptron algorithm can be used to learn the weights of a perceptron. For multilayer perceptron, the corresponding learning problem is way harder and it took a long time before a working solution was discovered. But eventually, one was invented: the so called backpropagation algorithm lead to a revival of neural networks in the late 1980s. It is still at the heart of many of the most advanced deep learning solutions."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Meanwhile in Helsinki...",description:"The path(s) leading to the backpropagation algorithm are rather long and winding. An interesting part of the history is related to the computer science department of the University of Helsinki. About three years after the founding of the department in 1967, <a href='http://people.idsia.ch/~juergen/linnainmaa1970thesis.pdf'>a Master’s thesis</a> was written by a student called Seppo Linnainmaa. The topic of the thesis was “Cumulative rounding error of algorithms as a Taylor approximation of individual rounding errors” (the thesis was written in Finnish, so this is a translation of the actual title “Algoritmin kumulatiivinen pyöristysvirhe yksittäisten pyöristysvirheiden Taylor-kehitelmänä”).<br><br>\nThe automatic differentiation method developed in the thesis was later applied by other researchers to quantify the sensitivity of the output of a multilayer neural network with respect to the individual weights, which is the key idea in backpropagation."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"A simple neural network classifier"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To give a relatively simple example of using a neural network classifier, we'll consider a task that is very similar to the MNIST digit recognition task, namely classifying images in two classes. We will first create a classifier to classify whether an image shows a cross (x) or a circle (o). Our images are represented here as pixels that are either colored or white, and the pixels are arranged in 5 × 5 grid. In this format our images of a cross and a circle (more like a diamond, to be honest) look like this:"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise23a",properties:{},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In order to build a neural network classifier, we need to formalise the problem in a way where we can solve it using the methods we have learned. Our first step is to represent the information in the pixels by a numerical values that can be used as the input to a classifier. Let's use 1 if the square is colored, and 0 if it is white. Note that although the symbols in the above graphic are of different color (green and blue), our classifier will ignore the color information and use only the colored/white information. The 25 pixels in the image make the inputs of our classifier."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To make sure that we know which pixel is which in the numerical representation, we can decide to list the pixels in the same order as you'd read text, so row by row from the top, and reading each row from left to right. The first row of the cross, for example, is represented as 1,0,0,0,1; the second row as 0,1,0,1,0, and so on. The full input for the cross input is then: 1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We'll use the basic neuron model where the first step is to compute a linear combination of the inputs. Thus need a weight for each of the input pixels, which means 25 weights in total."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Finally, we use the step activation function. If the linear combination is negative, the neuron activation is zero, which we decide to use to signify a cross. If the linear combination is positive, the neuron activation is one, which we decide to signify a circle."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Let's try what happens when all the weights take the same numerical value, 1. With this setup, our linear combination for the cross image will be 9 (9 colored pixels, so 9 × 1, and 16 white pixels, 16 × 0), and for the circle image it will be 8 (8 colored pixels, 8 × 1, and 17 white pixels, 17 × 0). In other words, the linear combination is positive for both images and they are thus classified as circles. Not a very good result given that there are only two images to classify."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To improve the result, we need to adjust the weights in such a way that the linear combination will negative for a cross and positive for a circle. If we think about what differentiates images of crosses and circles, we can see that circles have no colored pixels in the center of the image, whereas crosses do. Likewise, the pixels at the corners of the image are colored in the cross, but white in the circle."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We can now adjust the weights. There are an infinite number of weights that do the job. For example, assign weight -1 to the center pixel (the 13th pixel), and weight 1 to the pixels in the middle of each of the four sides of the image, letting all the other weights be 0. Now, for the cross input, the center pixel produce the value –1, while for all the other pixels either the pixel value of the weight is 0, so that –1 is also the total value. This leads to activation 0, and the cross is correctly classified."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"How about the circle then? Each of the pixels in the middle of the sides produces the value 1, which makes 4 × 1 = 4 in total. For all the other pixels either the pixel value or the weight is zero, so 4 is the total. Since 4 is a positive value, the activation is 1, and the circle is correctly recognized as well."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Happy or not?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We will now follow similar reasoning to build a classifier for smiley faces. You can assign weights to the input pixels in the image by clicking on them. Clicking once sets the weight to 1, and clicking again sets it to -1. The activation 1 indicates that the image is classified as a happy face, which can be correct or not, while activation –1 indicates that the image is classified as a sad face."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Don't be discouraged by the fact that you will not be able to classify all the smiley faces correctly: it is in fact impossible with our simple classifier! This is one important learning objective: sometimes perfect classification just isn't possible because the classifier is too simple. In this case the simple neuron that uses a linear combination of the inputs is too simple for the task. Observe how you can build classifiers that work well in different cases: some classify most of the happy faces correctly while being worse for sad faces, or the other way around."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Can you achieve 6/8 correct for both happy and sad faces?"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise23b",properties:{},children:[]},{type:"text",value:"\n"}]}],data:{quirksMode:!1}},excerpt:"If we have a neuron with six inputs (analogous to the amounts of the six shopping items: potatoes, carrots, and so on), input1, input…",frontmatter:{path:"/5/2",title:"How neural networks are built",part:5,type:"section",lang:"en",section:2}}},{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"In the previous section, we have discussed the basic ideas behind most neural network methods: multilayer networks, non-linear activation functions, and learning rules such as the backpropagation algorithm. "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"They power almost all modern neural network applications. However, there are some interesting and powerful variations of the theme that have lead to great advances in deep learning in many areas."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Convolutional neural networks (CNNs)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"One area where deep learning has achieved spectacular success is image processing. The simple classifier that we studied in detail in the previous section is severely limited – as you noticed it wasn't even possible to classify all the smiley faces correctly. By adding more layers in the network and using backpropagation to learn the weights does in principle solve the problem, but another one emerges: the number of weights becomes extremely large and consequently, the amount of training data required to achieve satisfactory accuracy can become too large to be realistic."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Fortunately, a very elegant solution to the problem of too many weights exists: a special kind of neural networks, or rather, a special kind of layer that can be included in a deep neural network. This special kind of layer is a so called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"convolutional layer"}]},{type:"text",value:". Networks including convolutional layers are called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"convolutional neural networks"}]},{type:"text",value:" (CNNs). Their key property is that they can detect image features such as bright or dark (or specific color) spots, edges in various orientations, patterns, and so on. These form the basis for detecting more abstract features such as a cat’s ears, a dog’s snout, a person’s eye, or the octagonal shape of a stop sign. It would normally be hard to train a neural network to detect such features based on the pixels of the input image, because the features can appear in different positions, different orientations, and in different sizes in the image: moving the object or the camera angle will change the pixel values dramatically even if the object itself looks just the same to us. In order to learn to detect a stop sign in all these different conditions would require vast of amounts of training data because the network would only detect the sign in conditions where it has appeared in the training data. So, for example, a stop sign in the top right corner of the image would be detected only if the training data included an image with the stop sign in the top right corner. CNNs can recognize the object anywhere in the image no matter where it has been observed in the training images."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Why we need CNNs",description:"CNNs use a clever trick to reduce the amount of training data required to detect objects in different conditions. The trick basically amounts to using the same input weights for many neurons — so that all of these neurons are activated by the same pattern — but with different input pixels. We can for example have a set of neurons that are activated by a cat’s pointy ear. When the input is a photo of a cat, two neurons are activated, one for the left ear and another for the right. We can also let the neuron’s input pixels be taken from a smaller or a larger area, so that different neurons are activated by the ear appearing in different scales (sizes), so that we can detect a small cat's ears even if the training data only included images of big cats."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The convolutional neurons are typically placed in the bottom layers of the network, which processes the raw input pixels. Basic neurons (like the perceptron neuron discussed above) are placed in the higher layers, which process the output of the bottom layers. The bottom layers can usually be trained using unsupervised learning, without a particular prediction task in mind. Their weights will be tuned to detect features that appear frequently in the input data. Thus, with photos of animals, typical features will be ears and snouts, whereas in images of buildings, the features are architectural components such as walls, roofs, windows, and so on. If a mix of various objects and scenes is used as the input data, then the features learned by the bottom layers will be more or less generic. This means that pre-trained convolutional layers can be reused in many different image processing tasks. This is extremely important since it is easy to get virtually unlimited amounts of unlabeled training data - images without labels - which can be used to train the bottom layers. The top layers are always trained by supervised machine learning techniques such as backpropagation."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"gan",color:"#00B5AA",frombottom:"0",totalheight:"54%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Do neural networks dream of electric sheep? Generative adversarial networks (GANs)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Having learned a neural network from data, it can be used for prediction. Since the top layers of the network have been trained in a supervised manner to perform a particular classification or prediction task, the top layers are really useful only for that task. A network trained to detect stop signs is useless for detecting handwritten digits or cats."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A fascinating result is obtained by taking the pre-trained bottom layers and studying what the features they have learned look like. This can be achieved by generating images that activate a certain set of neurons in the bottom layers. Looking at the generated images, we can see what the neural network “thinks” a particular feature looks like, or what an image with a select set of features in it would look like. Some even like to talk about the networks “dreaming” or “hallucinating” images (see Google’s "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/DeepDream"},children:[{type:"text",value:"DeepDream system"}]},{type:"text",value:")."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Be careful with metaphors",description:"However, we’d like to once again emphasize the problem with metaphors such as dreaming when simple optimization of the input image is meant — remember the suitcase words discussed in Chapter 1. The neural network doesn’t really dream, and it doesn’t have a concept of a cat that it would understand in a similar sense as a human understands. It is simply trained to recognize objects and it can generate images that are similar to the input data that it is trained on."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To actually generate real looking cats, human faces, or other objects (you’ll get whatever you used as the training data), "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/Ian_Goodfellow"},children:[{type:"text",value:"Ian Goodfellow"}]},{type:"text",value:" who currently works at Google Brain, proposed a clever combination of two neural networks. The idea is to let the two networks compete against each other. One of the networks is trained to generate images like the ones in the training data. The other network’s task is to separate images generated by the first network from real images from the training data — it is called the adversarial network, and the whole system is called generative adversarial network or a GAN."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The system trains the two models side by side. In the beginning of the training, the adversarial model has an easy task to tell apart the real images from the training data and the clumsy attempts by the generative model. However, as the generative network slowly gets better and better, the adversarial model has to improve as well, and the cycle continues until eventually the generated images are almost indistinguishable from real ones. The GAN tries to not only reproduce the images in the training data: that would be a way too simple strategy to beat the adversarial network. Rather, the system is trained so that it has to be able to generate new, real-looking images too."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"span",properties:{className:["gatsby-resp-image-wrapper"],style:"position: relative; display: block; ; max-width: 674px; margin-left: auto; margin-right: auto;"},children:[{type:"text",value:"\n    "},{type:"element",tagName:"span",properties:{className:["gatsby-resp-image-background-image"],style:"padding-bottom: 99.85163204747775%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAwH/2gAMAwEAAhADEAAAAevjtlOmE1znRMx54Q//xAAfEAACAQIHAAAAAAAAAAAAAAABAgMAEgQREyEiIzP/2gAIAQEAAQUC2YyANi5clkZiS3KrYjSHquOpN6//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAVEQEBAAAAAAAAAAAAAAAAAAABIP/aAAgBAgEBPwEI/8QAHhAAAgICAgMAAAAAAAAAAAAAAAECERIhIjFBcaH/2gAIAQEABj8CUq2O14GkScaqP0jLSbXdHPHIn7O9KK0SP//EABwQAQADAAIDAAAAAAAAAAAAAAEAESExQWFxgf/aAAgBAQABPyHhhDYsr2QNHyDgQeoJIatIIgNFtLq+deXEdoLZbC6Q17p//9oADAMBAAIAAwAAABCHOEH/xAAXEQEBAQEAAAAAAAAAAAAAAAABABEx/9oACAEDAQE/EFHMJ7bye3//xAAYEQEBAQEBAAAAAAAAAAAAAAABABEhMf/aAAgBAgEBPxBDdYOR4xf/xAAeEAEBAAICAgMAAAAAAAAAAAABEQAhMWFBUXGBof/aAAgBAQABPxBGlCPY2P5l/AUIunnB7HsJ1jTHsqzynrLGh7TUAnGJLNRQwaGXWsfVXT6QuIbQKaLLrOZLQ1+DP//Z'); background-size: cover; display: block;"},children:[{type:"text",value:"\n      "},{type:"element",tagName:"img",properties:{className:["gatsby-resp-image-image"],style:"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px transparent;",alt:"fakecelebrityfaces",title:"",src:"/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-c341a.jpg",srcSet:["/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-24b35.jpg 360w","/static/5_3_fake-celebrity-ac3753c9c9a3248de4bc71231b483be1-c341a.jpg 674w"],sizes:["(max-width:","674px)","100vw,","674px"]},children:[]},{type:"text",value:"\n    "}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The above images were generated by a GAN developed by NVIDIA in a project led by "},{type:"element",tagName:"a",properties:{href:"https://users.aalto.fi/~lehtinj7/"},children:[{type:"text",value:"Prof Jaakko Lehtinen"}]},{type:"text",value:" (see "},{type:"element",tagName:"a",properties:{href:"https://www.technologyreview.com/the-download/609290/meet-the-fake-celebrities-dreamed-up-by-ai/"},children:[{type:"text",value:"this article for more details"}]},{type:"text",value:")."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Could you have recognized them as fakes?"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"part-summary",properties:{chapter:"5",heading:"After completing Chapter 5 you should be able to:",listitems:'[ {"content":"Explain what a neural network is and where they are being successfully used"}, {"content":"Understand the technical methods that underpin neural networks"}]'},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]}],data:{quirksMode:!1}},excerpt:"They power almost all modern neural network applications. However, there are some interesting and powerful variations of the theme that have…",frontmatter:{path:"/5/3",title:"Advanced neural network techniques",part:5,type:"section",lang:"en",section:3}}}]},allParts:{totalCount:6,edges:[{node:{frontmatter:{title:"What is AI?",path:"/1",section:null,part:1,lang:"en",bannerImage:{publicURL:"/static/banner1-5cb707dcbce557b358c736c82a82b847.png"}}}},{node:{frontmatter:{title:"AI problem solving",path:"/2",section:null,part:2,lang:"en",bannerImage:{publicURL:"/static/banner2-3217219fe81de9c2f030e51f04557962.png"}}}},{node:{frontmatter:{title:"Real world AI",path:"/3",section:null,part:3,lang:"en",bannerImage:{publicURL:"/static/banner3-8433f94cdf930cb1172a332eda51a0ae.png"}}}},{node:{frontmatter:{title:"Machine learning",path:"/4",section:null,part:4,lang:"en",bannerImage:{publicURL:"/static/banner4-fdc0e4c1dc187a976325542364658e54.png"}}}},{node:{frontmatter:{title:"Neural networks",path:"/5",section:null,part:5,lang:"en",bannerImage:{publicURL:"/static/banner5-8d6d86ca3c422d98b6213f5ddfbe8c07.png"}}}},{node:{frontmatter:{title:"Implications",path:"/6",section:null,part:6,lang:"en",bannerImage:{publicURL:"/static/banner6-2943d36053a6dd8bd40b3dc3832bb0f8.png"}}}}]},currentPart:{htmlAst:{type:"root",children:[],data:{quirksMode:!1}},frontmatter:{path:"/5",title:"Neural networks",part:5,lang:"en",quote:"Areas like natural language and image processing have traditionally been sore points of AI. Neural networks and deep learning are being used to achieve significant improvements in these areas.",quoteAuthor:"",bannerImage:{publicURL:"/static/banner5-8d6d86ca3c422d98b6213f5ddfbe8c07.png"}}},allSections:{totalCount:18,edges:[{node:{frontmatter:{title:"How should we define AI?",path:"/1/1",section:1,part:1,lang:"en"
}}},{node:{frontmatter:{title:"Odds and probability",path:"/3/1",section:1,part:3,lang:"en"}}},{node:{frontmatter:{title:"Search and problem solving",path:"/2/1",section:1,part:2,lang:"en"}}},{node:{frontmatter:{title:"The types of machine learning",path:"/4/1",section:1,part:4,lang:"en"}}},{node:{frontmatter:{title:"About predicting the future",path:"/6/1",section:1,part:6,lang:"en"}}},{node:{frontmatter:{title:"Neural network basics",path:"/5/1",section:1,part:5,lang:"en"}}},{node:{frontmatter:{title:"Related fields",path:"/1/2",section:2,part:1,lang:"en"}}},{node:{frontmatter:{title:"The Bayes Rule",path:"/3/2",section:2,part:3,lang:"en"}}},{node:{frontmatter:{title:"Solving problems with AI",path:"/2/2",section:2,part:2,lang:"en"}}},{node:{frontmatter:{title:"The nearest neighbor classifier",path:"/4/2",section:2,part:4,lang:"en"}}},{node:{frontmatter:{title:"The societal implications of AI",path:"/6/2",section:2,part:6,lang:"en"}}},{node:{frontmatter:{title:"How neural networks are built",path:"/5/2",section:2,part:5,lang:"en"}}},{node:{frontmatter:{title:"Philosophy of AI",path:"/1/3",section:3,part:1,lang:"en"}}},{node:{frontmatter:{title:"Naive Bayes classification",path:"/3/3",section:3,part:3,lang:"en"}}},{node:{frontmatter:{title:"Search and games",path:"/2/3",section:3,part:2,lang:"en"}}},{node:{frontmatter:{title:"Summary",path:"/6/3",section:3,part:6,lang:"en"}}},{node:{frontmatter:{title:"Regression",path:"/4/3",section:3,part:4,lang:"en"}}},{node:{frontmatter:{title:"Advanced neural network techniques",path:"/5/3",section:3,part:5,lang:"en"}}}]}},pathContext:{part:5,type:"section",lang:"en"}}}});
//# sourceMappingURL=path---5-3-eb479f08b61876c9d9df.js.map