webpackJsonp([26039752902518],{1481:function(e,t){e.exports={data:{markdown:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"Handwritten digits are a classic case that is often used when discussing why we use machine learning, and we will make no exception."}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Below you can see examples of handwritten images from the very commonly used MNIST dataset."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"mnist"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:'The correct label (what digit the writer was supposed to write) is shown above each image. Note that some of the "correct” class labels are questionable: see for example the second image from left: is that really a 7, or actually a 4?'}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"MNIST – What's that?",description:"Every machine learning student knows about the MNIST dataset. Fewer know what the acronym stands for. In fact, we had to look it up to be able to tell you that the M stands for Modified, and NIST stands for National Institute of Standards and Technology. Now you probably know something that an average machine learning expert doesn’t!"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the most common machine learning problems, exactly one class value is correct at a time. This is also true in the MNIST case, although as we said, the correct answer may often be hard to tell. In this kind of problems, it is not possible that an instance belongs to multiple classes (or none at all) at the same time. What we would like to achieve is an AI method that can be given an image like the ones above, and automatically spit out the correct label (a number between 0 and 9)."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"How not to solve the problem",description:"An automatic digit recognizer could in principle be built manually by writing down rules such as:\n    <ul>\n    <li>if the black pixels are mostly in the form of a single loop then the label is 0</li>\n    <li>if the black pixels form two intersecting loops then the label is 8</li>\n    <li>if the black pixels are mostly in a straight vertical line in the middle of the figure then the label is 1</li>\n    </ul>\n    and so on...<br><br>\nThis was how AI methods were mostly developed in the 1980s (so called “expert systems”). However, even for such a simple task as digit recognition, the task of writing such rules is very laborious. In fact, the above example rules wouldn’t be specific enough to be implemented by programming – we’d have to define precisely what we mean by “mostly”, “loop”, “line”, “middle”, and so on.<br><br>\nAnd even if we did all this work, the result would likely be a bad AI method because as you can see, the handwritten digits are often a bit so-and-so, and every rule would need a dozen exceptions.\n"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Three types of machine learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The roots of machine learning are in statistics, which can also be thought of as the art of "},{type:"element",tagName:"b",properties:{},children:[{type:"text",value:"extracting knowledge from data"}]},{type:"text",value:". Especially methods such as linear regression and Bayesian statistics, which are both already more than two centuries old (!), are even today at the heart of machine learning. For more examples and a brief history, see the "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/Timeline_of_machine_learning"},children:[{type:"text",value:"timeline of machine learning"}]},{type:"text",value:" (Wikipedia)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The area of machine learning is often divided in subareas according to the kinds of problems being attacked. A rough categorisation is as follows:"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Supervised learning"}]},{type:"text",value:": We are given an input, for example a photograph with a traffic sign, and the task is to predict the correct output or label, for example which traffic sign is in the picture (speed limit, stop sign, ...). In the simplest cases, the answers are of the form yes/no. (We call these "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"binary classification problems"}]},{type:"text",value:".)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Unsupervised learning"}]},{type:"text",value:": There are no labels or correct outputs. The task is to discover the structure of the data: for example, grouping similar items to form “clusters”, or reducing the data to a small number of important “dimensions”. Data visualization can also be considered unsupervised learning."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Reinforcement learning"}]},{type:"text",value:": Commonly used in situations where an AI agent like a self-driving car must operate in an environment and where feedback about good or bad choices is available with some delay. Also used in games where the outcome may be decided only at the end of the game."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The categories are somewhat overlapping and fuzzy, so a particular method can sometimes be hard to place in one category. For example, as the name suggests, so called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"semisupervised learning"}]},{type:"text",value:" is partly supervised and partly unsupervised."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Classification",description:"When it comes to machine learning, we will focus primarily on supervised learning, and in particular, classification tasks. In classification, we observe in input, such as a photograph of a traffic sign, and try to infer its “class”, such as the type of sign (speed limit 80 km/h, pedestrian crossing, stop sign, ...). Other examples of classification tasks include: identification of fake Twitter accounts (input includes the list of followers, and the rate at which they have started following the account, and the class is either fake or real account) and handwritten digit recognition (input is an image, class is 0,...,9). "},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"supervised-learning"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Humans teaching machines: supervised learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Instead of manually writing down exact rules to do the classification, the point in supervised machine learning is to take a number of examples, label each one by the correct label, and use them to “train” an AI method to automatically recognize the correct label for the training examples as well as (at least hopefully) any other images. This of course requires that the correct labels are provided, which is why we talk about supervised learning. The user who provides the correct labels is a supervisor who guides the learning algorithm towards correct answers so that eventually, the algorithm can independently produce them."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In addition to learning how to predict the correct label in a classification problem, supervised learning can also be used in situations where the predicted outcome is a number. Examples include predicting the number of people who will click a Google ad based on the ad content and data about the user’s prior online behavior, predicting the number of traffic accidents based on road conditions and speed limit, or predicting the selling price of real estate based on its location, size, and condition. These problems are called "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"regression"}]},{type:"text",value:". You probably recognize the term "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"linear regression"}]},{type:"text",value:", which is a classical, still very popular technique for regression."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Example",description:"Suppose we have a data set consisting of apartment sales data. For each purchase, we would obviously have the price that was paid, together with the size of the apartment in square meters (or square feet, if you like), and the number of bedrooms, the year of construction, the condition (on a scale from “disaster“ to “spick and span”). We could then use machine learning to train a regression model that predicts the selling price based on these features. See <a href='http://kannattaakokauppa.fi/#/en/'>a real-life example here</a>"},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"price-real-estate",color:"#85a0ff",frombottom:"4%",totalheight:"81%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Caveat: Careful with that Machine Learning algorithm"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"There are a couple potential mistakes that we'd like to make you aware of. They are related to the fact that unless you are careful with the way you apply machine learning methods, you could become too confident about the accuracy of your predictions, and be heavily disappointed when the accuracy turns out to be worse than expected."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The first thing to keep in mind in order to avoid big mistakes, is to split your data set into two parts: the "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"training data"}]},{type:"text",value:" and the "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"test data"}]},{type:"text",value:". We first train the algorithm using only the training data. This gives us a model or a rule that predicts the output based on the input variables."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To assess how well we can actually predict the outputs, we can't count on the training data. While a model may be a very good predictor in the training data, it is no proof that it can "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"generalize"}]},{type:"text",value:" to any other data. This is where the test data comes in handy: we can apply the trained model to predict the outputs for the test data and compare the predictions to the actual outputs (for example, future apartment sale prices)."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Too fit to be true! Overfitting alert",description:"It is very important to keep in mind that the accuracy of a predictor learned by machine learning can be quite different in the training data and in separate test data. This is the so called <b>overfitting</b> phenomenon, and a lot of machine learning research is focused on avoiding it one way or another. Intuitively, overfitting means trying to be too smart. When predicting the success of a new song by a known artist, you can look at the track record of the artist's earlier songs, and come up with a rule like “if the song is about love, and includes a catchy chorus, it will be top-20“. However, maybe there are two love songs with catchy choruses that didn't make the top-20, so you decide to continue the rule “...except if Sweden or yoga are mentioned“ to improve your rule. This could make your rule fit the past data perfectly, but it could in fact make it work <b>worse on future test data</b>.<br><br>Machine learning methods are especially prone to overfitting because they can try a huge number of different “rules“ until one that fits the training data perfectly is found. Especially methods that are very flexible and can adapt to almost any pattern in the data can overfit unless the amount of data is enormous. For example, compared to quite restricted linear models obtained by linear regression, neural networks can require massive amounts of data before they produce reliable prediction."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Learning to avoid overfitting and choose a model that is not too restricted, nor too flexible, is one of the most essential skills of a data scientist."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Learning without a teacher: unsupervised learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Above we discussed supervised learning where the correct answers are available, and the task of the machine learning algorithm is to find a model that predicts them based on the input data."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In unsupervised learning, the correct answers are not provided. This makes the situation quite different since we can't build the model by making it fit the correct answers on training data. It also makes the evaluation of performance more complicated since we can't check whether the learned model is doing well or not."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Typical unsupervised learning methods attempt to learn some kind of “structure” underlying the data. This can mean, for example, "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"visualization"}]},{type:"text",value:" where similar items are placed near each other and dissimilar items further away from each other. It can also mean "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"clustering"}]},{type:"text",value:" where we use the data to identify groups or “clusters” of items that are similar to each other but dissimilar from data in other clusters."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Example",description:"As a concrete example, grocery store chains collect data about their customers' shopping behavior (that's why you have all those loyalty cards). To better understand their customers, the store can either visualize the data using a graph where each customer is represented by a dot and customers who tend to buy the same products are placed nearer each other than customers who buy different products. Or, the store could apply clustering to obtain a set of customer groups such as ‘low-budget health food enthusiasts’, ‘high-end fish lovers’, ‘soda and pizza 6 days a week’, and so on. Note that the machine learning method would only group the customers into clusters, but it wouldn't automatically generate the cluster labels (‘fish lovers’ and so on). This task would be left for the user."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Yet another example of unsupervised learning can be termed "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"generative modeling"}]},{type:"text",value:". This has become a prominent approach since the last few years as a deep learning technique called /generative adversarial networks/ (GANs) has lead to great advances. Given some data, for example, photographs of people's faces, a generative model can generate more of the same: more real-looking but artificial images of people's faces."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We will return to GANs and the implications of being able to produce high-quality artificial image content a bit later in the course, but next we will take a closer look at supervised learning and discuss some specific methods in more detail."}]}],data:{quirksMode:!1}},frontmatter:{path:"/4/1",title:"The types of machine learning",section:1,part:4,lang:"en"}},allRelatedSections:{totalCount:3,edges:[{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"Handwritten digits are a classic case that is often used when discussing why we use machine learning, and we will make no exception."}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Below you can see examples of handwritten images from the very commonly used MNIST dataset."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"mnist"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:'The correct label (what digit the writer was supposed to write) is shown above each image. Note that some of the "correct” class labels are questionable: see for example the second image from left: is that really a 7, or actually a 4?'}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"MNIST – What's that?",description:"Every machine learning student knows about the MNIST dataset. Fewer know what the acronym stands for. In fact, we had to look it up to be able to tell you that the M stands for Modified, and NIST stands for National Institute of Standards and Technology. Now you probably know something that an average machine learning expert doesn’t!"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the most common machine learning problems, exactly one class value is correct at a time. This is also true in the MNIST case, although as we said, the correct answer may often be hard to tell. In this kind of problems, it is not possible that an instance belongs to multiple classes (or none at all) at the same time. What we would like to achieve is an AI method that can be given an image like the ones above, and automatically spit out the correct label (a number between 0 and 9)."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"How not to solve the problem",description:"An automatic digit recognizer could in principle be built manually by writing down rules such as:\n    <ul>\n    <li>if the black pixels are mostly in the form of a single loop then the label is 0</li>\n    <li>if the black pixels form two intersecting loops then the label is 8</li>\n    <li>if the black pixels are mostly in a straight vertical line in the middle of the figure then the label is 1</li>\n    </ul>\n    and so on...<br><br>\nThis was how AI methods were mostly developed in the 1980s (so called “expert systems”). However, even for such a simple task as digit recognition, the task of writing such rules is very laborious. In fact, the above example rules wouldn’t be specific enough to be implemented by programming – we’d have to define precisely what we mean by “mostly”, “loop”, “line”, “middle”, and so on.<br><br>\nAnd even if we did all this work, the result would likely be a bad AI method because as you can see, the handwritten digits are often a bit so-and-so, and every rule would need a dozen exceptions.\n"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Three types of machine learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The roots of machine learning are in statistics, which can also be thought of as the art of "},{type:"element",tagName:"b",properties:{},children:[{type:"text",value:"extracting knowledge from data"}]},{type:"text",value:". Especially methods such as linear regression and Bayesian statistics, which are both already more than two centuries old (!), are even today at the heart of machine learning. For more examples and a brief history, see the "},{type:"element",tagName:"a",properties:{href:"https://en.wikipedia.org/wiki/Timeline_of_machine_learning"},children:[{type:"text",value:"timeline of machine learning"}]},{type:"text",value:" (Wikipedia)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The area of machine learning is often divided in subareas according to the kinds of problems being attacked. A rough categorisation is as follows:"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Supervised learning"}]},{type:"text",value:": We are given an input, for example a photograph with a traffic sign, and the task is to predict the correct output or label, for example which traffic sign is in the picture (speed limit, stop sign, ...). In the simplest cases, the answers are of the form yes/no. (We call these "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"binary classification problems"}]},{type:"text",value:".)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Unsupervised learning"}]},{type:"text",value:": There are no labels or correct outputs. The task is to discover the structure of the data: for example, grouping similar items to form “clusters”, or reducing the data to a small number of important “dimensions”. Data visualization can also be considered unsupervised learning."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"Reinforcement learning"}]},{type:"text",value:": Commonly used in situations where an AI agent like a self-driving car must operate in an environment and where feedback about good or bad choices is available with some delay. Also used in games where the outcome may be decided only at the end of the game."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The categories are somewhat overlapping and fuzzy, so a particular method can sometimes be hard to place in one category. For example, as the name suggests, so called "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"semisupervised learning"}]},{type:"text",value:" is partly supervised and partly unsupervised."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Classification",description:"When it comes to machine learning, we will focus primarily on supervised learning, and in particular, classification tasks. In classification, we observe in input, such as a photograph of a traffic sign, and try to infer its “class”, such as the type of sign (speed limit 80 km/h, pedestrian crossing, stop sign, ...). Other examples of classification tasks include: identification of fake Twitter accounts (input includes the list of followers, and the rate at which they have started following the account, and the class is either fake or real account) and handwritten digit recognition (input is an image, class is 0,...,9). "},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"supervised-learning"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Humans teaching machines: supervised learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Instead of manually writing down exact rules to do the classification, the point in supervised machine learning is to take a number of examples, label each one by the correct label, and use them to “train” an AI method to automatically recognize the correct label for the training examples as well as (at least hopefully) any other images. This of course requires that the correct labels are provided, which is why we talk about supervised learning. The user who provides the correct labels is a supervisor who guides the learning algorithm towards correct answers so that eventually, the algorithm can independently produce them."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In addition to learning how to predict the correct label in a classification problem, supervised learning can also be used in situations where the predicted outcome is a number. Examples include predicting the number of people who will click a Google ad based on the ad content and data about the user’s prior online behavior, predicting the number of traffic accidents based on road conditions and speed limit, or predicting the selling price of real estate based on its location, size, and condition. These problems are called "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"regression"}]},{type:"text",value:". You probably recognize the term "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"linear regression"}]},{type:"text",value:", which is a classical, still very popular technique for regression."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Example",description:"Suppose we have a data set consisting of apartment sales data. For each purchase, we would obviously have the price that was paid, together with the size of the apartment in square meters (or square feet, if you like), and the number of bedrooms, the year of construction, the condition (on a scale from “disaster“ to “spick and span”). We could then use machine learning to train a regression model that predicts the selling price based on these features. See <a href='http://kannattaakokauppa.fi/#/en/'>a real-life example here</a>"},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"price-real-estate",color:"#85a0ff",frombottom:"4%",totalheight:"81%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Caveat: Careful with that Machine Learning algorithm"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"There are a couple potential mistakes that we'd like to make you aware of. They are related to the fact that unless you are careful with the way you apply machine learning methods, you could become too confident about the accuracy of your predictions, and be heavily disappointed when the accuracy turns out to be worse than expected."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The first thing to keep in mind in order to avoid big mistakes, is to split your data set into two parts: the "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"training data"}]},{type:"text",value:" and the "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"test data"}]},{type:"text",value:". We first train the algorithm using only the training data. This gives us a model or a rule that predicts the output based on the input variables."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To assess how well we can actually predict the outputs, we can't count on the training data. While a model may be a very good predictor in the training data, it is no proof that it can "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"generalize"}]},{type:"text",value:" to any other data. This is where the test data comes in handy: we can apply the trained model to predict the outputs for the test data and compare the predictions to the actual outputs (for example, future apartment sale prices)."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Too fit to be true! Overfitting alert",description:"It is very important to keep in mind that the accuracy of a predictor learned by machine learning can be quite different in the training data and in separate test data. This is the so called <b>overfitting</b> phenomenon, and a lot of machine learning research is focused on avoiding it one way or another. Intuitively, overfitting means trying to be too smart. When predicting the success of a new song by a known artist, you can look at the track record of the artist's earlier songs, and come up with a rule like “if the song is about love, and includes a catchy chorus, it will be top-20“. However, maybe there are two love songs with catchy choruses that didn't make the top-20, so you decide to continue the rule “...except if Sweden or yoga are mentioned“ to improve your rule. This could make your rule fit the past data perfectly, but it could in fact make it work <b>worse on future test data</b>.<br><br>Machine learning methods are especially prone to overfitting because they can try a huge number of different “rules“ until one that fits the training data perfectly is found. Especially methods that are very flexible and can adapt to almost any pattern in the data can overfit unless the amount of data is enormous. For example, compared to quite restricted linear models obtained by linear regression, neural networks can require massive amounts of data before they produce reliable prediction."
},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Learning to avoid overfitting and choose a model that is not too restricted, nor too flexible, is one of the most essential skills of a data scientist."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Learning without a teacher: unsupervised learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Above we discussed supervised learning where the correct answers are available, and the task of the machine learning algorithm is to find a model that predicts them based on the input data."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In unsupervised learning, the correct answers are not provided. This makes the situation quite different since we can't build the model by making it fit the correct answers on training data. It also makes the evaluation of performance more complicated since we can't check whether the learned model is doing well or not."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Typical unsupervised learning methods attempt to learn some kind of “structure” underlying the data. This can mean, for example, "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"visualization"}]},{type:"text",value:" where similar items are placed near each other and dissimilar items further away from each other. It can also mean "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"clustering"}]},{type:"text",value:" where we use the data to identify groups or “clusters” of items that are similar to each other but dissimilar from data in other clusters."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Example",description:"As a concrete example, grocery store chains collect data about their customers' shopping behavior (that's why you have all those loyalty cards). To better understand their customers, the store can either visualize the data using a graph where each customer is represented by a dot and customers who tend to buy the same products are placed nearer each other than customers who buy different products. Or, the store could apply clustering to obtain a set of customer groups such as ‘low-budget health food enthusiasts’, ‘high-end fish lovers’, ‘soda and pizza 6 days a week’, and so on. Note that the machine learning method would only group the customers into clusters, but it wouldn't automatically generate the cluster labels (‘fish lovers’ and so on). This task would be left for the user."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Yet another example of unsupervised learning can be termed "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"generative modeling"}]},{type:"text",value:". This has become a prominent approach since the last few years as a deep learning technique called /generative adversarial networks/ (GANs) has lead to great advances. Given some data, for example, photographs of people's faces, a generative model can generate more of the same: more real-looking but artificial images of people's faces."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We will return to GANs and the implications of being able to produce high-quality artificial image content a bit later in the course, but next we will take a closer look at supervised learning and discuss some specific methods in more detail."}]}],data:{quirksMode:!1}},excerpt:"Below you can see examples of handwritten images from the very commonly used MNIST dataset. The correct label (what digit the writer was…",frontmatter:{path:"/4/1",title:"The types of machine learning",part:4,type:"section",lang:"en",section:1}}},{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"The nearest neighbor classifier is among the simplest possible classifiers. When given a item to classify, it finds the training data item that is most similar to the new item, and outputs its label. An example is given in the following diagram."}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"nearest-neighbor-graph"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the above diagram, we show a collection of training data items, some of which belong to one class (green) and other to another class (blue). In addition, there are two test data items, the stars, which we are going to classify using the nearest neighbor method."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The two test items are both classified in the “green” class because their nearest neighbors are both green (see diagram (b) above)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The position of the points in the plot represents in some way the properties of the items. Since we draw the diagram on a flat two-dimensional surface — you can move in two independent directions: up-down or left-right — the items have two properties that we can use for comparison. Imagine for example representing patients at a clinic in terms of their age and blood-sugar level. But the above diagram should be taken just as a visual tool to illustrate the general idea, which is to relate the class values to similarity or proximity (nearness). The general idea is by no means restricted to two dimensions and the nearest neighbor classifier can easily be applied to items that are characterized by many more properties than two."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"What do we mean by nearest?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"An interesting question related to (among other things) the nearest neighbor classifier is the definition of distance or similarity between instances. In the illustration above, we tacitly assumed that the standard geometric distance, technically called the Euclidean distance, is used. This simply means that if the points are drawn on a piece of paper (or displayed on your screen), you can measure the distance between any two items by pulling a piece of thread straight from one to the other and measuring the length."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Defining ‘nearest’",description:"Using the geometric distance to decide which is the nearest item may not always be reasonable or even possible: the type of the input may, for example, be text, where it is not clear how the items are drawn in a geometric representation and how distances should be measured. You should therefore choose the distance metric on a case-by-case basis. "},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the MNIST digit recognition case, one common way to measure image similarity is to count pixel-by-pixel matches. In other words, we compare the pixels in the top-left corner of each image to one another and if the more similar color (shade of gray) they are, the more similar the two images are. We also compare the pixels in the bottom-right corner of each image, and all pixels inbetween. This technique is quite sensitive to shifting or scaling the images: if we take an image of a '1' and shift it ever so slightly either left or right, the outcome is that the two images (before and after the shift) are very different because the black pixels are in different positions in the two images. Fortunately, the MNIST data has been preprocessed by centering the images so that this problem is alleviated."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"recommendation",color:"#ebe9ef",frombottom:"0",totalheight:"50%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Using nearest neighbors to predict user behavior"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A typical example of an application of the nearest neighbor method is predicting user behavior in AI applications such as recommendation systems."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The idea is to use the very simple principle that users with similar past behavior tend to have similar future behavior. Imagine a music recommendation system that collects data about users’ listening behavior. Let’s say you have listened to 1980s disco music (just for the sake of argument). One day, the service provider gets their hands on a hard-to-find 1980 disco classic, and add it into the music library. The system now needs to predict whether you will like it or not. One way of doing this is to use information about the genre, the artist, and other metadata, entered by the good people of the service provider. However, this information is relatively scarce and coarse and it will only be able to give rough predictions."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"What current recommendation systems use instead of the manually entered metadata, is something called collaborative filtering. The collaborative aspect of it is that it uses other users’ data to predict your preferences. The word “filter” refers to the fact that you will be only recommended content that passes through a filter: content that you are likely to enjoy will pass, other content will not. (This kind of filters may lead to the so called filter bubbles, which we mentioned in Chapter 1. We will return to them later.)"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Now let’s say that other users who have listened to 80s disco music enjoy the new release and keep listening to it again and again. The system will identify the similar past behavior that you and other 80s disco fanatics share, and since other users like you enjoy the new release, the system will predict that you will too. Hence it will show up at the top of your recommendation list. In an alternative reality, maybe the added song is not so great and other users with similar past behavior as yours don't really like it. In that case, the system wouldn't bother recommending it to you, or at least it wouldn't be at the top of the list of recommendations to you."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The following exercise will illustrate this idea."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"quiz",properties:{quizid:"5aec63af06ee0000047c59a4"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"illustrations",properties:{motive:"nearest-neighbor",color:"#ebe9ef",frombottom:"24.7%",totalheight:"63%"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the above example, we only had six users’ data and our prediction was probably very unreliable. However, online shopping sites often have millions users, and the amount of data they produce is massive. In many cases, there are a hoard of users whose past behavior is very similar to yours, and whose purchase history gives a pretty good indication of your interests."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"These predictions can also be self-fulfilling prophecies in the sense that you are more likely to buy a product if it is recommended to you by the system, which makes it tricky to evaluate how well they actually work. The same kind of recommendation systems are also used to recommend music, movies, news, and social media content to users. In the context of news and social media, filters created by such systems can lead to filter bubbles."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"quiz",properties:{quizid:"5aec65ec06ee0000047c59a9",peerreviewid:"5af3cb368125a40004605113"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]}],data:{quirksMode:!1}},excerpt:"In the above diagram, we show a collection of training data items, some of which belong to one class (green) and other to another class…",frontmatter:{path:"/4/2",title:"The nearest neighbor classifier",part:4,type:"section",lang:"en",section:2}}},{node:{htmlAst:{type:"root",children:[{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"lead",properties:{},children:[{type:"text",value:"Our main learning objective in this section is another nice example of supervised learning methods, and almost as simple as the nearest neighbor classifier too: linear regression. We'll introduce its close cousin, logistic regression as well.\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"The difference between classification and regression",description:"There is a small but important difference in the kind of predictions that we should produce in different scenarios. While for example the nearest neighbor classifier chooses a class label for any item out of a given set of alternatives (like spam/ham, or 0,1,2,...,9), linear regression produces a numerical prediction that is not constrained to be an integer (a whole number as opposed to something like 3.14). So linear regression is better suited in situations where the output variable can be any number like the price of a product, the distance to an obstacle, the box-office revenue of the next Star Wars movie, and so on."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The basic idea in linear regression is to add up the effects of each of the feature variables to produce the predicted value. The technical term for the adding up process is "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"linear combination"}]},{type:"text",value:". The idea is very straightforward, and it can be illustrated by your shopping bill."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Thinking of linear regression as a shopping bill",description:"Suppose you go to the grocery store and buy 2.5kg potatoes, 1.0kg carrots, and two bottles of milk. If the price of potatoes is 2€ per kg, the price of carrots is 4€ per kg, and a bottle of milk costs 3€, then the bill, calculated by the cashier, totals 2.5 × 2€ + 1.0 × 4€ + 2 × 3€ = 15€. In linear regression, the amount of potatoes, carrots, and milk are the inputs in the data. The output is the cost of your shopping, which clearly depends on both the price and how much of each product you buy."},children:[{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The word linear means that the increase in the output when one input feature is increased by some fixed amount is always the same. In other words, whenever you add, say, two kilos of carrots into your shopping basket, the bill goes up 8€. When you add another two kilos, the bill goes up another 8€, and if you add half as much, 1kg, the bill goes up exactly half as much, 4€."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"key-terminology",properties:{terminologies:'[\n      {"title":"Coefficients or weights","content":"In linear regression terminology, the prices of the different products would be called coefficients or weights. (This may appear confusing since we measured the amount of potatoes and carrots by weight, but not let yourself be tricked by this!) One of the main advantages of linear regression is its easy interpretability: the learned weights may in fact be more interesting than the predictions of the outputs.<br><br>For example, when we use linear regression to predict the life expectancy, the weight of smoking (cigarettes per day) is about minus half a year, meaning that smoking one cigarette more per day takes you on the average half a year closer to termination. Likewise, the weight of vegetable consumption (handful of vegetables per day) has weight plus one year, so eating a handful of greens gives every day gives you on the average one more year."}\n  ]'},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"quiz",properties:{quizid:"5aec62f306ee0000047c59a1"},children:[{type:"text",value:"\n"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"In the above exercise, the life expectancy of non-smoking, veggie-hating women, 80 years, was the starting point for the calculation. The technical term for the starting point is the "},{type:"element",tagName:"strong",properties:{},children:[{type:"text",value:"intercept"}]},{type:"text",value:". We will return to this below when we discuss how to learn linear regression models from data."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Learning linear regression"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Above, we discussed how predictions are obtained from linear regression when both the weights and the input features are known. So we are given the inputs and the weight, and we can produce the predicted output."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"When we are given the inputs and the outputs for a number of items, we can find the weights such that the predicted output matches the actual output as well as possible. This is the task solved by machine learning."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Example",description:"Continuing the shopping analogy, suppose we were given the contents of a number of shopping baskets and the total bill for each of them, and we were asked to figure out the price of each of the products (potatoes, carrots, and so on). From one basket, say 1kg of sirloin steak, 2kg of carrots, and a bottle of Chianti, even if we knew that the total bill is 35€, we couldn't determine the prices because there are many sets of prices that will yield the same total bill. With many baskets, however, we will usually be able to solve the problem."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"But the problem is made harder by the fact that in the real-world, the actual output isn’t always fully determined by the input, because of various factors that introduce uncertainty or “noise” into the process. You can think of shopping at a bazaar where the prices for any given product may vary from time to time, or a restaurant where the final damage includes a variable amount of tip. In such situations, we can estimate the prices but only with some limited accuracy."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Finding the weights that optimize the match between the predicted and the actual outputs in the training data is a classical statistical problem dating back to the 1800s, and it can be easily solved even for massive data sets."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"We will not go into the details of the actual weight-finding algorithms, such as the classical least squares technique, simple as they are. However, you can get a feel of finding trends in data in the following exercises."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Visualising linear regression"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"A good way to get a feel for what linear regression can tell us is to draw a chart containing our data and our regression results. As a simple toy example our data set has one variable, the number of cups of coffee an employee drinks per day, and the number on lines of code written per day by that employee as the output. This is not a real data set as obviously there are other factors having an effect on the productivity of an employee other than coffee that interact in complex ways. The increase in productivity by increasing the amount of coffee will also hold only to a certain point after which the jitters distract too much."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"linearreg",properties:{},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"When we present our data in the chart above as points where one point represents one employee, we can see that there is obviously a trend that drinking more coffee results in more lines of code being written. (Recall that this is completely made-up data.) From this data set we can learn the coefficient, or the weight, related to coffee consumption, and by eye we can already say that it seems to be somewhere close to five, since for each cup of coffee consumed the number of lines programmed seems to go up rougly by five. For example, employees who drink around two cups of coffee per day seem to produce around 20 lines of code per day, and similarly at four cups of coffee, the amount of lines produced is around 30."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"It can also be noted that employees who do not drink coffee at all\nalso produce code, and is shown by the graph to be about ten lines. This number is the intercept term that we mentioned earlier. The intercept is another parameter in the model just like the weights are, that can be learned from the data. Just as in the life expectancy example it can be thought of as the starting point of our calculations before we have added in the effects of the input variable, or variables if we have more than one, be it coffee cups in this example, or cigarettes and vegetables in the previous one."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The line in the chart represents our predicted outcome, where we have estimated the intercept and the coefficient by using an actual linear regression technique called least squares. This line can be used to predict the number of lines produced when the input is the number of cups of coffee. Note that we can obtain a prediction even if we allow only partial cups (like half, 1/4 cups, and so on)."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise17",properties:{quizid:"5aec626406ee0000047c599e"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise18",properties:{quizid:"5aec61cd06ee0000047c599d"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"It should be pointed out that studies like those used in the above exercises cannot identify causal relationships. In other words, from this data alone, it is impossible to say whether studying actually increases life expectancy through better informed and healthier life-style or other mechanisms, or whether the apparent association between life expectancy and education is due to underlying factors that affects both. It is likely that, for example, in countries where people tend to be highly educated, nutrition, healthcare, and safety are also better, which increases life expectancy. With this kind of simple analysis, we can only identify associations, which can nevertheless be useful for prediction."}]},{type:"text",value:"\n"},{type:"element",tagName:"h3",properties:{},children:[{type:"text",value:"Machine learning applications of linear regression"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Linear regression is truly the workhorse of many AI and data science applications. It has its limits but they are often compensated by its simplicity, interpretability and efficiency. Linear regression has been successfully used in the following problems to give a few examples:"}]},{type:"text",value:"\n"},{type:"element",tagName:"ul",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of click rates in online advertising"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of retail demand for products"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of box-office revenue of Hollywood movies"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of software cost"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of insurance cost"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of crime rates"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"prediction of real estate prices"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Could we use regression to predict labels?"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"As we discussed above, linear regression and the nearest neighbor method produce different kinds of predictions. Linear regression outputs numerical outputs while the nearest neighbor method produces labels from a fixed set of alternatives (“classes”)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Where linear regression excels compared to nearest neighbors, is interpretability. What do we mean by this? You could say that in a way, the nearest neighbor method and any single prediction that it produces are easy to interpret: it’s just the nearest training data element! This is true, but when it comes to the interpretability of the learned model, there is a clear difference. Interpreting the trained model in nearest neighbors in a similar fashion as the weights in linear regression is impossible: the learned model is basically the whole data, and it is usually way too big and complex to provide us with much insight. So what if we’d like to have a method that produces the same kind of outputs as the nearest neighbor, labels, but is interpretable like linear regression?"}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"Logistic regression to the rescue"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Well there are good news for you: we can turn the linear regression method’s outputs into predictions about labels. The technique for doing this is called logistic regression. We will not go into the technicalities, suffice to say that in the simplest case, we take the output from linear regression, which is a number, and predict one label A if the label is more than zero, and another label B if the label is less than or equal to zero. Actually, instead of just predicting one class or another, logistic regression can also give us a measure of uncertainty of the prediction. So if we are predicting whether a customer will buy a new smartphone this year, we can get a prediction that customer A will buy a phone with probability 90%, but for another, less predictable customer, we can get a prediction that they will "},{type:"element",tagName:"i",properties:{},children:[{type:"text",value:"not"}]},{type:"text",value:" buy a phone with 55% probability (or in other words, that they will buy one with 45% probability)."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"It is also possible to use the same trick to obtain predictions over more than two possible labels, so instead of always predicting either yes or no (buy a new phone or not, fake news or real news, and so forth), we can use logistic regression to identify, for example, handwritten digits, in which case there are ten possible labels."}]},{type:"text",value:"\n"},{type:"element",tagName:"h3",properties:{},children:[{type:"text",value:"An example of logistic regression"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Let’s suppose that we collect data of students taking an introductory course in cookery. In addition to the basic information such as the student id, name, and so on, we also ask the students to report how many hours they studied for the exam (however you study for a cookery exam, probably cooking?) - and hope that they are more or less honest in their reports. After the exam, we will know whether each student passed the course or not. Some data points are presented below:"}]},{type:"text",value:"\n"},{type:"element",tagName:"table",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"tbody",properties:{},children:[{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"th",properties:{},children:[{type:"text",value:"Student ID"}]},{type:"text",value:"\n    "},{type:"element",tagName:"th",properties:{},children:[{type:"text",value:"Hours studied"}]},{type:"text",value:"\n    "},{type:"element",tagName:"th",properties:{},children:[{type:"text",value:"Pass/fail"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"24"
}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"15"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Pass"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"41"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"9.5"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Pass"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"58"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"2"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Fail"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"101"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"5"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Fail"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"103"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"6.5"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Fail"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n  "},{type:"element",tagName:"tr",properties:{},children:[{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"215"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"6"}]},{type:"text",value:"\n    "},{type:"element",tagName:"td",properties:{},children:[{type:"text",value:"Pass"}]},{type:"text",value:"\n  "}]},{type:"text",value:"\n"}]}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Based on the table, what kind of conclusion could you draw between the hours studied and passing the exam? We could think that if we have data from hundreds of students, maybe we could see the amount needed to study in order to pass the course.\nWe can present this data in a chart as you can see below."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"exercise19",properties:{quizid:"5aec615c06ee0000047c599b"},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Logistic regression is also used in a great variety of real-world AI applications such predicting financial risks, medical studies, and so on. However, like linear regression, it is also constrained by the linearity property and we need many other methods in our toolbox. We will return to the linearity issue later when we discuss neural networks."}]},{type:"text",value:"\n"},{type:"element",tagName:"h2",properties:{},children:[{type:"text",value:"The limits of machine learning"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"To summarize, machine learning is a very powerful tool for building AI applications. In addition to the nearest neighbor method, linear regression, and logistic regression, there are literally hundreds, if not thousands, of different machine learning techniques, but they all boil down to the same thing: trying to extract patterns and dependencies from data and using them either to gain understanding of a phenomenon or to predict future outcomes."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Machine learning can be a very hard problem and we can’t usually achieve a perfect method that would always produce the correct label. However, in most cases, a good but not perfect prediction is still better than none. Sometimes we may be able to produce better predictions by ourselves but we may still prefer to use machine learning because the machine will make its predictions faster and it will also keep churning out predictions without getting tired. Good examples are recommendation systems that need to predict what music, what videos, or what ads are more likely to be of interest to you."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"The factors that affect how good a result we can achieve include:"}]},{type:"text",value:"\n"},{type:"element",tagName:"ul",properties:{},children:[{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"The hardness of the task: in handwritten digit recognition, if the digits are written very sloppily, even a human can’t always guess correctly what the writer intended"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"The machine learning method: some methods are far better for a particular task than others"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"The amount of training data: from only a few examples, it is impossible to obtain a good classifier"}]},{type:"text",value:"\n"},{type:"element",tagName:"li",properties:{},children:[{type:"text",value:"The quality of the data"}]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"note",properties:{heading:"Data quality matters",description:"In the beginning of this Chapter, we emphasized the importance of having enough data and the risks of overfitting. Another equally important factor is the <b>quality</b> of the data. In order to build a model that generalises well to data outside of the training data, the training data needs to contain enough information that is relevant to the problem at hand. For example, if you create an image classifier that tells you what the image given to the algorithm is about, and you have trained it only on pictures of dogs and cats, it will assign everything it sees as either a dog or a cat. This would make sense if the algorithm is used in an environment where it will only see cats and dogs, but not if it is expected to see boats, cars, and flowers as well.<br><br>We'll return to potential problems caused by ”biased” data."},children:[]},{type:"text",value:"\n"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"It is also important to emphasize that different machine learning methods are suitable for different tasks. Thus, there is no single best method for all problems (“one algorithm to rule them all...”). Fortunately, one can try out a large number of different methods and see which one of them works best in the problem at hand."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"This leads us to a point that is very important but often overlooked in practice: what it means to work better. In the digit recognition task, a good method would of course produce the correct label most of the time. We can measure this by the classification error: the fraction of cases where our classifier outputs the wrong class. In predicting apartment prices, the quality measure is typically something like the difference between the predicted price and the final price for which the apartment is sold. In many real-life applications, it is also worse to err in one direction than in another: setting the price too high may delay the process by months, but setting the price too low will mean less money for the seller. And to take yet another example, failing to detect a pedestrian in front of a car is a far worse error than falsely detecting one when there is none."}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"As mentioned above, we can’t usually achieve zero error, but perhaps we will be happy with error less than 1 in 100 (or 1%). This too depends on the application: you wouldn’t be happy to have only 99% safe cars on the streets, but being able to predict whether you’ll like a new song with that accuracy may be more than enough for a pleasant listening experience. Keeping the actual goal in mind at all times helps us make sure that we create actual added value."}]},{type:"text",value:"\n"},{type:"element",tagName:"div",properties:{},children:[{type:"text",value:"\n  "},{type:"element",tagName:"part-summary",properties:{chapter:"4",heading:"After completing Chapter 4 you should be able to:",listitems:'[\n  {"content":"Explain why machine learning techniques are used"},\n  {"content":"Distinguish between unsupervised and supervised machine learning scenarios"},\n  {"content":"Explain the principles of three supervised classification methods: the nearest neighbor method, linear regression, and logistic regression"}\n    ]'},children:[{type:"text",value:">\n  "}]},{type:"text",value:"\n"}]}],data:{quirksMode:!1}},excerpt:"The basic idea in linear regression is to add up the effects of each of the feature variables to produce the predicted value. The technical…",frontmatter:{path:"/4/3",title:"Regression",part:4,type:"section",lang:"en",section:3}}}]},allParts:{totalCount:6,edges:[{node:{frontmatter:{title:"What is AI?",path:"/1",section:null,part:1,lang:"en",bannerImage:{publicURL:"/static/banner1-5cb707dcbce557b358c736c82a82b847.png"}}}},{node:{frontmatter:{title:"AI problem solving",path:"/2",section:null,part:2,lang:"en",bannerImage:{publicURL:"/static/banner2-3217219fe81de9c2f030e51f04557962.png"}}}},{node:{frontmatter:{title:"Real world AI",path:"/3",section:null,part:3,lang:"en",bannerImage:{publicURL:"/static/banner3-8433f94cdf930cb1172a332eda51a0ae.png"}}}},{node:{frontmatter:{title:"Machine learning",path:"/4",section:null,part:4,lang:"en",bannerImage:{publicURL:"/static/banner4-fdc0e4c1dc187a976325542364658e54.png"}}}},{node:{frontmatter:{title:"Neural networks",path:"/5",section:null,part:5,lang:"en",bannerImage:{publicURL:"/static/banner5-8d6d86ca3c422d98b6213f5ddfbe8c07.png"}}}},{node:{frontmatter:{title:"Implications",path:"/6",section:null,part:6,lang:"en",bannerImage:{publicURL:"/static/banner6-2943d36053a6dd8bd40b3dc3832bb0f8.png"}}}}]},currentPart:{htmlAst:{type:"root",children:[],data:{quirksMode:!1}},frontmatter:{path:"/4",title:"Machine learning",part:4,lang:"en",quote:"It has been long understood that learning is a key element of intelligence. This holds both for natural intelligence - we all get smarter by learning - and artificial intelligence.",quoteAuthor:"",bannerImage:{publicURL:"/static/banner4-fdc0e4c1dc187a976325542364658e54.png"}}},allSections:{totalCount:18,edges:[{node:{frontmatter:{title:"How should we define AI?",path:"/1/1",section:1,part:1,lang:"en"}}},{node:{frontmatter:{title:"Odds and probability",path:"/3/1",section:1,part:3,lang:"en"}}},{node:{frontmatter:{title:"Search and problem solving",path:"/2/1",section:1,part:2,lang:"en"}}},{node:{frontmatter:{title:"The types of machine learning",path:"/4/1",section:1,part:4,lang:"en"}}},{node:{frontmatter:{title:"About predicting the future",path:"/6/1",section:1,part:6,lang:"en"}}},{node:{frontmatter:{title:"Neural network basics",path:"/5/1",section:1,part:5,lang:"en"}}},{node:{frontmatter:{title:"Related fields",path:"/1/2",section:2,part:1,lang:"en"}}},{node:{frontmatter:{title:"The Bayes Rule",path:"/3/2",section:2,part:3,lang:"en"}}},{node:{frontmatter:{title:"Solving problems with AI",path:"/2/2",section:2,part:2,lang:"en"}}},{node:{frontmatter:{title:"The nearest neighbor classifier",path:"/4/2",section:2,part:4,lang:"en"}}},{node:{frontmatter:{title:"The societal implications of AI",path:"/6/2",section:2,part:6,lang:"en"}}},{node:{frontmatter:{title:"How neural networks are built",path:"/5/2",section:2,part:5,lang:"en"}}},{node:{frontmatter:{title:"Philosophy of AI",path:"/1/3",section:3,part:1,lang:"en"}}},{node:{frontmatter:{title:"Naive Bayes classification",path:"/3/3",section:3,part:3,lang:"en"}}},{node:{frontmatter:{title:"Search and games",path:"/2/3",section:3,part:2,lang:"en"}}},{node:{frontmatter:{title:"Summary",path:"/6/3",section:3,part:6,lang:"en"}}},{node:{frontmatter:{title:"Regression",path:"/4/3",section:3,part:4,lang:"en"}}},{node:{frontmatter:{title:"Advanced neural network techniques",path:"/5/3",section:3,part:5,lang:"en"}}}]}},pathContext:{part:4,type:"section",lang:"en"}}}});
//# sourceMappingURL=path---4-1-41a1eda897920e68f1f5.js.map